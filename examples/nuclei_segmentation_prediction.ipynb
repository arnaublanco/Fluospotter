{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13aa8d6e-1b8b-421d-9640-fb70d3c8b87b",
   "metadata": {},
   "source": [
    "# Train custom nuclei segmentation model\n",
    "\n",
    "In the following, we describe how to train our proposed nuclei segmentation model with your custom data using fluospotter.\n",
    "\n",
    "First, we need to install fluospotter if not installed:\n",
    "\n",
    "`pip install fluospotter`\n",
    "\n",
    "Or alternatively:\n",
    "\n",
    "`pip install https://github.com/arnaublanco/Fluospotter`\n",
    "\n",
    "Secondly, we need to load your data, we can do so by placing the data as TIF files with format (depth, height, width), that is, a stack of 2D images, in the folders called `train`, `valid` and `test`.\n",
    "\n",
    "&nbsp;\n",
    "<img src=\"images/test_folder.png\" width=700>\n",
    "&nbsp;\n",
    "\n",
    "We need to ensure that the ratio train/validation/test is approximately 75/15/10. For example, if I had 20 volumes, the ratio would be 15 volumes for training, 3 volumes for validation and 2 for testing, as shown in the following image.\n",
    "\n",
    "&nbsp;\n",
    "<img src=\"images/test_folder_data.png\" width=700>\n",
    "&nbsp;\n",
    "\n",
    "Nonetheless, the ratio will ultimately depend on you, but this is a fair starting point. Similarly, we need another folder with the masks/labels containing the exact same three folders (e.g. `labels`). Therefore:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e5ff6a-70c1-4b36-9e02-07db897936fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fluospotter.datasets import Dataset\n",
    "\n",
    "data = Dataset(data_dir=\"data\", segmentation_dir=\"labels\", training=True) # Here we specify the root folders, which in our case are `data` and `labels` that contains the three folders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df92953-1a10-421a-9b97-b460867e55cc",
   "metadata": {},
   "source": [
    "It's important that that the data in `data` and `labels` have the same name so that fluospotter can match them. For example, `Location-03.tif` in `data/test` will be matched with `Location-03.tif` in `labels/test`. If it can't be matched, an error will be raised.\n",
    "\n",
    "Now, we need to create an instance of a model, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6b9c97-a0e5-427b-a4b3-7990555afe36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We specify the configuration of the model with several set parameters\n",
    "cfg = {\n",
    "    \"learning_rate\": \"1e-3\",\n",
    "    \"patch_size\": \"48/256/256\",\n",
    "    \"n_samples\": 12,\n",
    "    \"vl_interval\": 5,\n",
    "    \"n_classes\": 2,\n",
    "    \"im_size\": \"49/256/256\",\n",
    "    \"alpha1\": 1.0,\n",
    "    \"alpha2\": 1.0,\n",
    "    \"loss1\": \"dice\",\n",
    "    \"loss2\": \"cedice\",\n",
    "    \"n_epochs\": 10,\n",
    "    \"neg_samples\": 1\n",
    "}\n",
    "\n",
    "model = SegmentationModel(model_name=\"dynunet\", configuration=cfg)\n",
    "model.train(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e58bb24-1a58-4344-8d84-b6b46bdbd862",
   "metadata": {},
   "source": [
    "Finally, to segment the data, we simply need to call the `predict` method, which returns the corresponding predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d021d2b-e32d-49d9-a7da-d258280cbf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ca27cc-1a8e-41de-a516-0694e6e1e9d8",
   "metadata": {},
   "source": [
    "### Alternative (directly with a `numpy.array`)\n",
    "\n",
    "If our data is already loaded, for example, in a `numpy.array`, we can alternatively use the `predict_image` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa31b15e-41ee-416b-ba65-cfad4dbfc749",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ... # Our data in a `numpy.array` format with (n_volumes, depth, height, width)\n",
    "\n",
    "preds = model.predict_image(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
